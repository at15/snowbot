{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cornell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[#6](https://github.com/at15/snowbot/issues/6) exporle [Cornell Move Corpus](https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html), kaggle seems to have a (non-official) [cleaner version](https://www.kaggle.com/Cornell-University/movie-dialog-corpus) with detail explanation, [Currie32/Chatbot-from-Movie-Dialogue](https://github.com/Currie32/Chatbot-from-Movie-Dialogue) and [stanford cs20si/chatbot](https://github.com/chiphuyen/stanford-tensorflow-tutorials/blob/master/assignments/chatbot/data.py) show how to preprocess this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chameleons.pdf                 movie_lines.txt            README.txt\r\n",
      "movie_characters_metadata.txt  movie_titles_metadata.txt\r\n",
      "movie_conversations.txt        raw_script_urls.txt\r\n"
     ]
    }
   ],
   "source": [
    "ls cornell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- separator is '+++$+++', so we can't use pd.read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: it seems I can't use pd.read_csv\n",
    "# In addition, separators longer than 1 character and different from '\\s+' will be interpreted as regular expressions and will also force the use of the Python parsing engin\n",
    "# movie_titles_metadata = pd.read_csv('cornell/movie_titles_metadata.txt', sep='++++++')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_titles_metadata.txt 617\n",
      "movie_characters_metadata.txt 9035\n",
      "movie_lines.txt 304713\n",
      "movie_conversations.txt 83097\n"
     ]
    }
   ],
   "source": [
    "def line_count(file):\n",
    "    count = 0\n",
    "    # NOTE: it has encoding problem, we have to ignore it ....\n",
    "    with open(file, errors='ignore') as f:\n",
    "        for line in f:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "files = ['movie_titles_metadata.txt', 'movie_characters_metadata.txt', 'movie_lines.txt', 'movie_conversations.txt']\n",
    "for f in files:\n",
    "    print(f, line_count('cornell/' + f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion is, user1, user2, movie, lines [u1, u2, u1, u2] NOTE: it may not be an even number, some pepople just [ignore it for one turn QA](https://github.com/suriyadeepan/datasets/blob/master/seq2seq/cornell_movie_corpus/scripts/prepare_data.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_head(file, lines=10):\n",
    "    with open(file, errors='ignore') as f:\n",
    "        for i in range(lines):\n",
    "            print(i, f.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.c1        c2        movie       lines\n",
      "0 u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']\n",
      "\n",
      "1 u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L198', 'L199']\n",
      "\n",
      "2 u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L200', 'L201', 'L202', 'L203']\n",
      "\n",
      "3 u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L204', 'L205', 'L206']\n",
      "\n",
      "4 u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L207', 'L208']\n",
      "\n",
      "5 u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L271', 'L272', 'L273', 'L274', 'L275']\n",
      "\n",
      "6 u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L276', 'L277']\n",
      "\n",
      "7 u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L280', 'L281']\n",
      "\n",
      "8 u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L363', 'L364']\n",
      "\n",
      "9 u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L365', 'L366']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('No.c1        c2        movie       lines')\n",
    "file_head('cornell/movie_conversations.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.line    characterID    movie   character name   text(utterance)\n",
      "0 L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\n",
      "\n",
      "1 L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\n",
      "\n",
      "2 L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.\n",
      "\n",
      "3 L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?\n",
      "\n",
      "4 L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\n",
      "\n",
      "5 L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow\n",
      "\n",
      "6 L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.\n",
      "\n",
      "7 L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No\n",
      "\n",
      "8 L870 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I'm kidding.  You know how sometimes you just become this \"persona\"?  And you don't know how to quit?\n",
      "\n",
      "9 L869 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Like my fear of wearing pastels?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('No.line    characterID    movie   character name   text(utterance)')\n",
    "file_head('cornell/movie_lines.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can convert those files to a more readable in memory structure and save it to csv\n",
    "\n",
    "- conversations: uid, uid, mid, line ids\n",
    "- lines: number, uid, mid, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>mid</th>\n",
       "      <th>lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>['L194', 'L195', 'L196', 'L197']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>['L198', 'L199']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>['L200', 'L201', 'L202', 'L203']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>['L204', 'L205', 'L206']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>['L207', 'L208']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   c1  c2  mid                             lines\n",
       "0   0   2    0  ['L194', 'L195', 'L196', 'L197']\n",
       "1   0   2    0                  ['L198', 'L199']\n",
       "2   0   2    0  ['L200', 'L201', 'L202', 'L203']\n",
       "3   0   2    0          ['L204', 'L205', 'L206']\n",
       "4   0   2    0                  ['L207', 'L208']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# process conversations\n",
    "conversations = []\n",
    "conversation_lines = []\n",
    "with open('cornell/movie_conversations.txt') as f:\n",
    "    for line in f:\n",
    "        cells = line.split('+++$+++')\n",
    "        cells = [c.strip() for c in cells]\n",
    "        conv = (int(cells[0][1:]), int(cells[1][1:]), int(cells[2][1:]), cells[3])\n",
    "        conversations.append(conv)\n",
    "        conversation_lines.append([c.strip() for c in cells[3].replace('\\'', '')[1:-1].split(',')])\n",
    "conv_df = pd.DataFrame.from_records(conversations, \n",
    "                                    columns=['c1', 'c2', 'mid', 'lines'])\n",
    "conv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>mid</th>\n",
       "      <th>lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>83097</td>\n",
       "      <td>83097</td>\n",
       "      <td>83097</td>\n",
       "      <td>83097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5420</td>\n",
       "      <td>5608</td>\n",
       "      <td>617</td>\n",
       "      <td>83097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>4331</td>\n",
       "      <td>1475</td>\n",
       "      <td>289</td>\n",
       "      <td>['L127507', 'L127508', 'L127509', 'L127510', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>193</td>\n",
       "      <td>187</td>\n",
       "      <td>338</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           c1     c2    mid                                              lines\n",
       "count   83097  83097  83097                                              83097\n",
       "unique   5420   5608    617                                              83097\n",
       "top      4331   1475    289  ['L127507', 'L127508', 'L127509', 'L127510', '...\n",
       "freq      193    187    338                                                  1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_df.c1 = conv_df.c1.astype('category')\n",
    "conv_df.c2 = conv_df.c2.astype('category')\n",
    "conv_df.mid = conv_df.mid.astype('category')\n",
    "conv_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split one conversation into multiple QA, like `['L204', 'L205', 'L206']` becomes two QA `(L204, L205), (L205, L206)`, we didn't simply take the odd one as question and even one as response like [suriyadeepan/dataset does](https://github.com/suriyadeepan/datasets/blob/master/seq2seq/cornell_movie_corpus/scripts/prepare_data.py#L48-L60), the latter way gives half QA pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304713"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn lines into dictionary, key is line i.e. L204, value is the utterance (text) i.e. How you doing\n",
    "line2text = {}\n",
    "with open('cornell/movie_lines.txt', errors='ignore') as f:\n",
    "    for line in f:\n",
    "        cells = line.split('+++$+++')\n",
    "        cells = [c.strip() for c in cells]\n",
    "        line2text[cells[0]] = cells[4]\n",
    "len(line2text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221616\n",
      "221616\n"
     ]
    }
   ],
   "source": [
    "questions = []\n",
    "answers = []\n",
    "for conv in conversation_lines:\n",
    "    for i in range(len(conv) - 1):\n",
    "        questions.append(line2text[conv[i]])\n",
    "        answers.append(line2text[conv[i+1]])\n",
    "print(len(questions))\n",
    "print(len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\n",
      "A: Well, I thought we'd start with pronunciation, if that's okay with you. \n",
      "\n",
      "Q: Well, I thought we'd start with pronunciation, if that's okay with you.\n",
      "A: Not the hacking and gagging and spitting part.  Please. \n",
      "\n",
      "Q: Not the hacking and gagging and spitting part.  Please.\n",
      "A: Okay... then how 'bout we try out some French cuisine.  Saturday?  Night? \n",
      "\n",
      "Q: You're asking me out.  That's so cute. What's your name again?\n",
      "A: Forget it. \n",
      "\n",
      "Q: No, no, it's my fault -- we didn't have a proper introduction ---\n",
      "A: Cameron. \n",
      "\n",
      "Q: Cameron.\n",
      "A: The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    print('Q:', questions[i])\n",
    "    print('A:', answers[i], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: now we need to clean text, remove things like -, split it into words, and turn words to id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
